{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06ba7a1f",
   "metadata": {},
   "source": [
    "\n",
    "# üìä Speedtest Telemetry ‚Äî Exploratory Analysis\n",
    "\n",
    "This notebook loads and analyzes your `speedtest.csv` produced by the speedtest-logger script.\n",
    "\n",
    "**Expected columns**\n",
    "- `timestamp` (string or ISO datetime)\n",
    "- `download_mbps`, `upload_mbps`\n",
    "- `ping_ms`, `jitter_ms`\n",
    "- `packet_loss` (percentage or fraction)\n",
    "- `server_name`, `server_id`\n",
    "- `isp`\n",
    "- `status` (ok/error)\n",
    "- `error` (optional message)\n",
    "\n",
    "> Tip: If your CSV has different headers, set `COLUMN_MAP` below to rename them on load.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f86d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Config ----\n",
    "from pathlib import Path\n",
    "\n",
    "# Default path assumes this notebook lives in: <repo_root>/notebooks/\n",
    "# and CSV is in: <repo_root>/data/speedtest.csv\n",
    "DEFAULT_CSV = (Path.cwd().parent / \"data\" / \"speedtest.csv\")\n",
    "\n",
    "# Alternatively, override with an absolute path:\n",
    "# DEFAULT_CSV = Path(\"/home/youruser/speedtest-logs/data/speedtest.csv\")\n",
    "\n",
    "# Map your CSV headers to canonical names if needed\n",
    "COLUMN_MAP = {\n",
    "    # 'dl': 'download_mbps',\n",
    "    # 'ul': 'upload_mbps',\n",
    "    # 'latency_ms': 'ping_ms',\n",
    "}\n",
    "\n",
    "DEFAULT_CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67032ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_path = Path(DEFAULT_CSV)\n",
    "assert csv_path.exists(), f\"CSV not found: {csv_path}\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "if COLUMN_MAP:\n",
    "    df = df.rename(columns=COLUMN_MAP)\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# Parse time\n",
    "if 'timestamp' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    df = df.sort_values('timestamp')\n",
    "else:\n",
    "    raise ValueError(\"Expected a 'timestamp' column.\")\n",
    "\n",
    "# Ensure numeric columns\n",
    "for col in ['download_mbps','upload_mbps','ping_ms','jitter_ms','packet_loss']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Clean obvious outliers (optional thresholds; tweak as needed)\n",
    "df['packet_loss'] = df['packet_loss'].clip(lower=0) if 'packet_loss' in df.columns else np.nan\n",
    "\n",
    "# Derive time features\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['dow']  = df['timestamp'].dt.day_name()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c0cbc",
   "metadata": {},
   "source": [
    "## üìê Basic Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary = {}\n",
    "for col in ['download_mbps','upload_mbps','ping_ms','jitter_ms','packet_loss']:\n",
    "    if col in df.columns:\n",
    "        summary[col] = df[col].describe(percentiles=[0.1,0.25,0.5,0.75,0.9,0.95]).to_dict()\n",
    "pd.DataFrame(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aaa896",
   "metadata": {},
   "source": [
    "## üïí Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e4a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ts_plot(series, ylabel):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(df['timestamp'], series)\n",
    "    plt.title(ylabel + ' over time')\n",
    "    plt.xlabel('timestamp')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if 'download_mbps' in df.columns:\n",
    "    ts_plot(df['download_mbps'], 'Download (Mbps)')\n",
    "\n",
    "if 'upload_mbps' in df.columns:\n",
    "    ts_plot(df['upload_mbps'], 'Upload (Mbps)')\n",
    "\n",
    "if 'ping_ms' in df.columns:\n",
    "    ts_plot(df['ping_ms'], 'Latency (ms)')\n",
    "\n",
    "if 'jitter_ms' in df.columns:\n",
    "    ts_plot(df['jitter_ms'], 'Jitter (ms)')\n",
    "\n",
    "if 'packet_loss' in df.columns:\n",
    "    ts_plot(df['packet_loss'], 'Packet Loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4790af",
   "metadata": {},
   "source": [
    "## üìà Rolling Averages (noise reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73443b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use a 5-sample rolling window; adjust to your cadence\n",
    "if 'download_mbps' in df.columns:\n",
    "    df['dl_roll'] = df['download_mbps'].rolling(window=5, min_periods=1).mean()\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(df['timestamp'], df['download_mbps'], alpha=0.4, label='raw')\n",
    "    plt.plot(df['timestamp'], df['dl_roll'], label='rolling(5)')\n",
    "    plt.title('Download (Mbps): raw vs rolling mean')\n",
    "    plt.xlabel('timestamp')\n",
    "    plt.ylabel('Mbps')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if 'upload_mbps' in df.columns:\n",
    "    df['ul_roll'] = df['upload_mbps'].rolling(window=5, min_periods=1).mean()\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(df['timestamp'], df['upload_mbps'], alpha=0.4, label='raw')\n",
    "    plt.plot(df['timestamp'], df['ul_roll'], label='rolling(5)')\n",
    "    plt.title('Upload (Mbps): raw vs rolling mean')\n",
    "    plt.xlabel('timestamp')\n",
    "    plt.ylabel('Mbps')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df5ea4",
   "metadata": {},
   "source": [
    "## ‚è∞ Aggregations by Hour & Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agg_hour = df.groupby('hour').agg(\n",
    "    dl=('download_mbps','mean'),\n",
    "    ul=('upload_mbps','mean'),\n",
    "    ping=('ping_ms','mean'),\n",
    "    jitter=('jitter_ms','mean'),\n",
    "    loss=('packet_loss','mean')\n",
    ")\n",
    "display(agg_hour)\n",
    "\n",
    "agg_day = df.groupby('date').agg(\n",
    "    dl=('download_mbps','mean'),\n",
    "    ul=('upload_mbps','mean'),\n",
    "    ping=('ping_ms','mean'),\n",
    "    jitter=('jitter_ms','mean'),\n",
    "    loss=('packet_loss','mean')\n",
    ")\n",
    "display(agg_day.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8f6304",
   "metadata": {},
   "source": [
    "## üñ•Ô∏è Server/ISP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'server_name' in df.columns:\n",
    "    server_perf = df.groupby('server_name').agg(\n",
    "        tests=('server_name','count'),\n",
    "        dl=('download_mbps','median'),\n",
    "        ul=('upload_mbps','median'),\n",
    "        ping=('ping_ms','median'),\n",
    "        loss=('packet_loss','median')\n",
    "    ).sort_values('tests', ascending=False)\n",
    "    display(server_perf.head(10))\n",
    "\n",
    "if 'isp' in df.columns:\n",
    "    isp_perf = df.groupby('isp').agg(\n",
    "        tests=('isp','count'),\n",
    "        dl=('download_mbps','median'),\n",
    "        ul=('upload_mbps','median'),\n",
    "        ping=('ping_ms','median'),\n",
    "        loss=('packet_loss','median')\n",
    "    ).sort_values('tests', ascending=False)\n",
    "    display(isp_perf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130a39f",
   "metadata": {},
   "source": [
    "## üö® Outage & Degradation Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DL_MIN = 10   # Mbps thresholds; tune for your expected service\n",
    "UL_MIN = 5\n",
    "MAX_PING = 200  # ms\n",
    "MAX_LOSS = 5.0  # percent\n",
    "\n",
    "alerts = []\n",
    "\n",
    "if 'download_mbps' in df.columns:\n",
    "    alerts.append(df['download_mbps'] < DL_MIN)\n",
    "if 'upload_mbps' in df.columns:\n",
    "    alerts.append(df['upload_mbps'] < UL_MIN)\n",
    "if 'ping_ms' in df.columns:\n",
    "    alerts.append(df['ping_ms'] > MAX_PING)\n",
    "if 'packet_loss' in df.columns:\n",
    "    alerts.append(df['packet_loss'] > MAX_LOSS)\n",
    "\n",
    "if alerts:\n",
    "    import numpy as np\n",
    "    bad = np.logical_or.reduce(alerts)\n",
    "    cols = [c for c in ['timestamp','download_mbps','upload_mbps','ping_ms','jitter_ms','packet_loss','server_name','server_id','status','error'] if c in df.columns]\n",
    "    issues = df.loc[bad, cols].copy()\n",
    "    display(issues.tail(20))\n",
    "else:\n",
    "    print(\"No alert conditions defined or columns missing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a63d77c",
   "metadata": {},
   "source": [
    "## üíæ Save a cleaned/enhanced CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ab751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_path = (Path.cwd().parent / 'data' / 'speedtest_cleaned.csv')\n",
    "save_cols = [c for c in ['timestamp','download_mbps','upload_mbps','ping_ms','jitter_ms','packet_loss','server_name','server_id','isp','status','error','dl_roll','ul_roll','date','hour','dow'] if c in df.columns]\n",
    "df.to_csv(out_path, index=False, columns=save_cols)\n",
    "out_path\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
